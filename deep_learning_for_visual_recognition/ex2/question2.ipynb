{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bittestenv2condac837ae6fc91f4a09b58a085a4be9e2e7",
   "display_name": "Python 3.8.3 64-bit ('test_env_2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Practical Part,\n",
    "Question 2;\n",
    "\n",
    "CÃ¼neyt Erem,\n",
    "Ulvi Shukurzade,\n",
    "Ewald Bindereif,\n",
    "Bilge Ulusay"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True, download=True, transform = transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False, download=True, transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 256, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, input_num, hidden, output):\n",
    "        super(net, self).__init__()\n",
    "        self.input_num = input_num\n",
    "        self.dense1 = nn.Linear(input_num, hidden[0])\n",
    "        self.dense2 = nn.Linear(hidden[0], hidden[1])\n",
    "        self.dense3 = nn.Linear(hidden[1], output)     \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), self.input_num)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "model = net(32*32*3, (100, 30), 10).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 1 and loss: 2.2759455530548096\n",
      "epoch: 2 and loss: 2.197988823928833\n",
      "epoch: 3 and loss: 2.101746180648804\n",
      "epoch: 4 and loss: 2.0205129978942873\n",
      "epoch: 5 and loss: 1.9629383893585206\n",
      "epoch: 6 and loss: 1.923136226234436\n",
      "epoch: 7 and loss: 1.8945437591171264\n",
      "epoch: 8 and loss: 1.8718334380340576\n",
      "epoch: 9 and loss: 1.8515281462860107\n",
      "epoch: 10 and loss: 1.8314786031341552\n",
      "epoch: 11 and loss: 1.8147729556274415\n",
      "epoch: 12 and loss: 1.7983118844223023\n",
      "epoch: 13 and loss: 1.7851604546356201\n",
      "epoch: 14 and loss: 1.7710650454711914\n",
      "epoch: 15 and loss: 1.7591964093780517\n",
      "epoch: 16 and loss: 1.7471750217056274\n",
      "epoch: 17 and loss: 1.7353364950942993\n",
      "epoch: 18 and loss: 1.7257641005706787\n",
      "epoch: 19 and loss: 1.7145941128540039\n",
      "epoch: 20 and loss: 1.7031203366851806\n",
      "epoch: 21 and loss: 1.692553325881958\n",
      "epoch: 22 and loss: 1.6812345377349853\n",
      "epoch: 23 and loss: 1.6730034964370728\n",
      "epoch: 24 and loss: 1.663301162147522\n",
      "epoch: 25 and loss: 1.6537054229736328\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    loss_rate = 0.\n",
    "    for image_train, label_train in train_loader:\n",
    "        image_train = image_train.float().to(DEVICE)\n",
    "        label_train = label_train.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output_label = model(image_train)\n",
    "        loss = criterion(output_label, label_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_rate += loss.item()*image_train.size(0)\n",
    "    loss_rate = loss_rate/len(train_loader.dataset)\n",
    "    print(\"epoch: {} and loss: {}\".format(i+1, loss_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number: 0 and accuracy: 0.511\nnumber: 1 and accuracy: 0.418\nnumber: 2 and accuracy: 0.309\nnumber: 3 and accuracy: 0.072\nnumber: 4 and accuracy: 0.361\nnumber: 5 and accuracy: 0.271\nnumber: 6 and accuracy: 0.504\nnumber: 7 and accuracy: 0.583\nnumber: 8 and accuracy: 0.471\nnumber: 9 and accuracy: 0.521\ntotal accuracy score: 0.0625\ntotal loss: 1.6280784606933594\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "true_num = [0.]*10\n",
    "total_num = [0.]*10\n",
    "loss_rate2 = 0.\n",
    "\n",
    "for image_test, label_test in test_loader:\n",
    "    image_test = image_test.float().to(DEVICE)\n",
    "    label_test = label_test.to(DEVICE)\n",
    "    optimizer.zero_grad()\n",
    "    output_label = model(image_test)\n",
    "    loss_rate2 += loss.item()*image_test.size(0)\n",
    "    _, label_pred = torch.max(output_label, 1)\n",
    "    label_pred = label_pred.cpu().numpy()\n",
    "    label_correct_rate = torch.tensor([True if label_pred[i] == label_test[i] else False for i in range(len(label_test))]).cpu().numpy()\n",
    "    for i in range(len(label_test)):\n",
    "        true_num[label_test.data[i]] += label_correct_rate[i].item()\n",
    "        total_num[label_test.data[i]] += 1\n",
    "for i in range(10):\n",
    "    if total_num[i] > 0:\n",
    "        print(\"number: {} and accuracy: {}\".format(i, true_num[i]/total_num[i]))\n",
    "print(\"total accuracy score: {}\".format(accuracy_score(label_correct_rate, label_pred)))\n",
    "loss_rate2 = loss_rate2/len(test_loader.dataset)\n",
    "print(\"total loss: {}\".format(loss_rate2))"
   ]
  },
  {
   "source": [
    "Explanation;\n",
    "\n",
    "Here, we set our model as input with 32*32 with 3 neuron to regulate it for input size, 2 hidden layers with 100 and 30 to keep in same number of layers but increase the number of neurones to show effects of number of neurons and same size 10 neurons for output. Then we used the same learning rate 0.01 and SDG optimization, Relu activation function to optimize in better between 0 and 1 interval than sigmoid. If we incerase the batch size to 256 or number of hidden layers by 1, then performance inreases a bit. Still our accuracy is a bit better than signle linear classification because MLP increases the learning rate, however selecting the correct number of inputs, hidden layers, batch sizes are important so that it is not best result by these results. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}