{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "def plotting_losses(cnn, cnn_batch_norm):\n",
    "    plt.plot(cnn.detach(), 'r', label=\"CNN\")\n",
    "    plt.plot(cnn_batch_norm.detach(), 'k', label=\"CNN with Batch Norm\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def acc_plot(cnn, cnn_batch_norm):\n",
    "    plt.plot(cnn, 'r', label=\"CNN\")\n",
    "    plt.plot(cnn_batch_norm, 'k', label=\"CNN with Batch Norm\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_images(images):\n",
    "    for image in images:\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The transforms chosen by us are `RandomHorizontalFlip`, `RandomRotation`, `Random Affine`, `ColorJitter`and finally `Normalize`.\n",
    "These transforms were chosen because they do not drastically change the features of the image but make the model more robust since the photos are now randomly rotated and flipped thus increasing the datatset and the model gets to learn the features better.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, images: torch.Tensor, labels: torch.Tensor, mode: str):\n",
    "        self.mode = mode\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.train_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                   transforms.RandomHorizontalFlip(0.3), # FLips the image w.r.t horizontal axis\n",
    "                                                   transforms.RandomRotation(10),     #Rotates the image to a specified angel\n",
    "                                                   transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
    "                                                   transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
    "                                                   transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n",
    "                                                   transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                                        std=[0.5, 0.5, 0.5])]) #Normalize all the images\n",
    "\n",
    "\n",
    "\n",
    "        self.test_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                                 ])\n",
    "    def __len__(self):\n",
    "        a = len(self.labels)\n",
    "        return a\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         image = self.images[index]\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        if self.mode == \"train\":\n",
    "            image = self.train_transform(image)\n",
    "        elif self.mode == \"test\":\n",
    "            image = self.test_transform(image)\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "dataset_x = datasets.CIFAR10(root = \"../cifar/\", train = True, download = False)\n",
    "dataset_y = datasets.CIFAR10(root = \"../cifar/\", train = False, download = False)\n",
    "train_dataset = Dataset(dataset_x.data, dataset_x.targets, \"train\")\n",
    "test_dataset = Dataset(dataset_y.data, dataset_y.targets, \"test\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128, shuffle = True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 128, shuffle = True, pin_memory=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_before = dataset_x[0][0]\n",
    "image_after = train_dataset[0][0].transpose(0,2)\n",
    "images = [image_before, image_after]\n",
    "plot_images(images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
    "\n",
    "        x = torch.randn(32,32,3).view(-1,3,32,32)\n",
    "\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc = nn.Linear(self._to_linear, 10)\n",
    "\n",
    "    def convs(self,x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x , (2,2))\n",
    "\n",
    "        #Block 2\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x , (2,2))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader):\n",
    "    for x,y in dataloader:\n",
    "        x, y = x.to('cuda:0'), y.to('cuda:0')\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model.forward(x)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        output_loss = loss(prediction, y)\n",
    "        output_loss.backward()\n",
    "        optimizer.step()\n",
    "    return output_loss\n",
    "\n",
    "def accuracy(model, dataloader):\n",
    "    hits = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to('cuda:0'), y.to('cuda:0')\n",
    "            prediction = model.forward(x)\n",
    "            prediction = torch.argmax(prediction, dim=1)\n",
    "            hits += (prediction == y).count_nonzero()\n",
    "    acc = hits / len(dataloader.dataset)\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "def training(model_factory, dataloader, optimizer_factory, epochs):\n",
    "    losses = torch.zeros(epochs)\n",
    "    accuracies = torch.zeros(epochs)\n",
    "    model = model_factory.to('cuda:0')\n",
    "    optimizer = optimizer_factory\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        losses[epoch] = train(model, optimizer, dataloader)\n",
    "        accuracies[epoch] = accuracy(model, test_loader)\n",
    "        sleep(0.1)\n",
    "        print(f\"Loss of Epoch {epoch} is {losses[epoch]}\")\n",
    "        print(f\"Accuracy of Epoch {epoch} is {accuracies[epoch]}\")\n",
    "    return losses, accuracies\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "class Network_Norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        x = torch.randn(32,32,3).view(-1,3,32,32)\n",
    "\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc = nn.Linear(self._to_linear, 10)\n",
    "\n",
    "    def convs(self,x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.bn1(self.conv2(x)))\n",
    "        x = F.max_pool2d(x , (2,2))\n",
    "\n",
    "        #Block 2\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.bn2(self.conv4(x)))\n",
    "        x = F.max_pool2d(x , (2,2))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def convs_test(self,x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x , (2,2))\n",
    "\n",
    "        #Block 2\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x , (2,2))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward_test(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "def train_fc(model, optimizer, dataloader, batch:bool):\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to('cuda:0'), y.to('cuda:0')\n",
    "        optimizer.zero_grad()\n",
    "        if batch == True:\n",
    "            prediction = model.forward(x)\n",
    "        else:\n",
    "            prediction = model.forward_test(x)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        output_loss = loss(prediction, y.to(torch.long))\n",
    "        output_loss.backward()\n",
    "        optimizer.step()\n",
    "    return output_loss\n",
    "\n",
    "def accuracy_fc(model, dataloader):\n",
    "    hits = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to('cuda:0'), y.to('cuda:0')\n",
    "            prediction = model.forward_test(x)\n",
    "            prediction = torch.argmax(prediction, dim=1)\n",
    "            hits += (prediction == y).count_nonzero()\n",
    "    acc = hits / len(dataloader.dataset)\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "def batch_norm(model_factory, optimizer_factory, dataloader, epochs):\n",
    "    losses = torch.zeros(epochs)\n",
    "    accuracies = torch.zeros(epochs)\n",
    "    model = model_factory.to('cuda:0')\n",
    "    optimizer = optimizer_factory\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        losses[epoch] = train_fc(model, optimizer, dataloader, True)\n",
    "        accuracies[epoch] = accuracy_fc(model, test_loader)\n",
    "        print(f\"The loss of {epoch} is {losses[epoch]}\")\n",
    "        print(f\"The accuracy of {epoch} is {accuracies[epoch]}\")\n",
    "        sleep(0.1)\n",
    "    return losses, accuracies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [18:33<00:00, 44.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of 0 is 1.1879993677139282\n",
      "The accuracy of 0 is 0.5891000032424927\n",
      "The loss of 1 is 1.1618212461471558\n",
      "The accuracy of 1 is 0.6593999862670898\n",
      "The loss of 2 is 1.1951428651809692\n",
      "The accuracy of 2 is 0.699999988079071\n",
      "The loss of 3 is 0.7369775772094727\n",
      "The accuracy of 3 is 0.7213999629020691\n",
      "The loss of 4 is 1.0667788982391357\n",
      "The accuracy of 4 is 0.7357999682426453\n",
      "The loss of 5 is 0.8239547610282898\n",
      "The accuracy of 5 is 0.7447999715805054\n",
      "The loss of 6 is 0.7277995347976685\n",
      "The accuracy of 6 is 0.7509999871253967\n",
      "The loss of 7 is 1.0218677520751953\n",
      "The accuracy of 7 is 0.7577999830245972\n",
      "The loss of 8 is 0.7566356658935547\n",
      "The accuracy of 8 is 0.7710999846458435\n",
      "The loss of 9 is 0.7046812772750854\n",
      "The accuracy of 9 is 0.7698999643325806\n",
      "The loss of 10 is 0.6197318434715271\n",
      "The accuracy of 10 is 0.7683999538421631\n",
      "The loss of 11 is 0.7447744011878967\n",
      "The accuracy of 11 is 0.7787999510765076\n",
      "The loss of 12 is 0.7398411631584167\n",
      "The accuracy of 12 is 0.7834999561309814\n",
      "The loss of 13 is 0.7597280740737915\n",
      "The accuracy of 13 is 0.7853999733924866\n",
      "The loss of 14 is 0.6412031054496765\n",
      "The accuracy of 14 is 0.7871999740600586\n",
      "The loss of 15 is 0.7972347736358643\n",
      "The accuracy of 15 is 0.7926999926567078\n",
      "The loss of 16 is 0.595268189907074\n",
      "The accuracy of 16 is 0.7876999974250793\n",
      "The loss of 17 is 0.5276250839233398\n",
      "The accuracy of 17 is 0.7998999953269958\n",
      "The loss of 18 is 0.5413842797279358\n",
      "The accuracy of 18 is 0.79339998960495\n",
      "The loss of 19 is 0.7399529218673706\n",
      "The accuracy of 19 is 0.7940999865531921\n",
      "The loss of 20 is 0.6851559281349182\n",
      "The accuracy of 20 is 0.8057000041007996\n",
      "The loss of 21 is 0.591948926448822\n",
      "The accuracy of 21 is 0.8054999709129333\n",
      "The loss of 22 is 0.46531981229782104\n",
      "The accuracy of 22 is 0.8007000088691711\n",
      "The loss of 23 is 0.7986966371536255\n",
      "The accuracy of 23 is 0.7981999516487122\n",
      "The loss of 24 is 0.4624585509300232\n",
      "The accuracy of 24 is 0.8023999929428101\n"
     ]
    }
   ],
   "source": [
    "model1 = Network_Norm()\n",
    "optimizer1  = optim.Adam(model1.parameters(), lr= 0.0005, betas= (0.9, 0.95))\n",
    "batch_losses, batch_accuracies = batch_norm(model1, optimizer1, train_loader, 25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Task C-1\n",
    "\n",
    "dataset_y2 = datasets.CIFAR10(root = \"../cifar/\", train = False, download = False,transform=transforms.ToTensor())\n",
    "\n",
    "image_index=random.randint(0,len(dataset_y2))\n",
    "random_image=dataset_y[image_index][0]\n",
    "plot_images([random_image])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)): tensor([[[[ 1.1176e-01,  7.0454e-02,  3.3013e-03,  ...,  1.1585e-01,\n",
      "            9.2761e-02,  1.6904e-01],\n",
      "          [ 1.1466e-01,  7.7015e-02,  4.6184e-02,  ...,  1.9135e-01,\n",
      "            1.5999e-01,  2.8286e-01],\n",
      "          [ 6.6823e-02,  1.8657e-02,  1.4041e-01,  ...,  2.1153e-01,\n",
      "            1.9827e-01,  2.2522e-01],\n",
      "          ...,\n",
      "          [ 1.3468e-01,  1.5978e-01,  1.6859e-01,  ...,  1.2335e-01,\n",
      "            1.2318e-01,  1.5762e-01],\n",
      "          [ 1.4615e-01,  1.5639e-01,  1.5146e-01,  ...,  1.2392e-01,\n",
      "            1.2454e-01,  1.2665e-01],\n",
      "          [ 1.4203e-01,  1.4705e-01,  1.3871e-01,  ...,  9.1934e-02,\n",
      "            1.6253e-01,  1.7076e-01]],\n",
      "\n",
      "         [[-4.2830e-02,  1.4185e-01,  4.0907e-01,  ...,  7.2556e-02,\n",
      "            9.9743e-02, -1.9621e-01],\n",
      "          [ 9.8495e-02,  2.6926e-01,  3.3010e-01,  ..., -3.2396e-03,\n",
      "           -1.8183e-02, -3.1712e-01],\n",
      "          [ 1.1465e-01,  2.8086e-01,  5.9726e-02,  ..., -3.2557e-02,\n",
      "           -1.3149e-01, -2.9211e-01],\n",
      "          ...,\n",
      "          [ 1.6723e-02, -1.9555e-02, -3.0987e-03,  ..., -1.0080e-02,\n",
      "            1.7603e-02, -3.0409e-02],\n",
      "          [-1.3410e-02, -3.6593e-02, -4.2971e-03,  ...,  3.0584e-02,\n",
      "            1.5591e-03, -3.7134e-02],\n",
      "          [-3.1849e-02, -1.9802e-02, -1.5178e-02,  ...,  1.9616e-02,\n",
      "           -4.4570e-02, -4.7755e-02]],\n",
      "\n",
      "         [[ 2.8378e-01,  3.3868e-01,  5.3511e-01,  ...,  1.7914e-01,\n",
      "            2.9242e-01,  5.5852e-02],\n",
      "          [ 2.0315e-01,  4.1535e-01,  4.5193e-01,  ...,  1.3338e-01,\n",
      "            2.1273e-01, -6.7726e-02],\n",
      "          [ 3.0960e-01,  4.3807e-01,  1.8211e-01,  ...,  1.8262e-01,\n",
      "            1.4962e-01,  7.3336e-03],\n",
      "          ...,\n",
      "          [ 2.1004e-01,  1.7292e-01,  1.9893e-01,  ...,  2.3698e-01,\n",
      "            1.8432e-01,  1.6826e-01],\n",
      "          [ 1.8038e-01,  1.6943e-01,  1.8049e-01,  ...,  2.4174e-01,\n",
      "            2.1765e-01,  1.6188e-01],\n",
      "          [ 1.5131e-01,  1.9343e-01,  2.2428e-01,  ...,  2.1988e-01,\n",
      "            1.2161e-01,  1.2923e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7226e-01, -1.1918e-01, -9.0307e-02,  ..., -1.5800e-02,\n",
      "           -7.5268e-02, -8.7483e-02],\n",
      "          [-5.2148e-02, -8.4424e-02, -8.2954e-02,  ..., -1.0667e-01,\n",
      "           -1.1234e-01, -9.3699e-02],\n",
      "          [-9.6161e-02, -1.1961e-01, -5.9788e-02,  ..., -1.5400e-01,\n",
      "           -1.1006e-01, -1.4591e-01],\n",
      "          ...,\n",
      "          [-9.1047e-02, -9.2031e-02, -1.2096e-01,  ..., -1.2369e-01,\n",
      "           -1.0494e-01, -9.4383e-02],\n",
      "          [-9.6226e-02, -1.0507e-01, -1.1074e-01,  ..., -1.0526e-01,\n",
      "           -8.3846e-02, -9.7357e-02],\n",
      "          [-7.3459e-02, -1.0133e-01, -8.4400e-02,  ..., -8.9629e-02,\n",
      "           -9.0331e-02, -9.2780e-02]],\n",
      "\n",
      "         [[-1.1165e-02, -3.5564e-04,  3.1637e-02,  ..., -7.4556e-02,\n",
      "           -7.6980e-02, -1.3710e-01],\n",
      "          [-3.8266e-02, -5.4699e-03, -4.7517e-02,  ..., -6.8338e-02,\n",
      "           -7.9133e-02, -1.0117e-01],\n",
      "          [-2.0841e-03, -2.5554e-03, -1.0559e-01,  ..., -4.9648e-02,\n",
      "           -4.0160e-02, -5.3188e-02],\n",
      "          ...,\n",
      "          [-5.1547e-02, -6.3191e-02, -5.9662e-02,  ..., -3.0719e-02,\n",
      "           -6.1339e-02, -3.7902e-02],\n",
      "          [-6.8083e-02, -7.1878e-02, -8.9093e-02,  ..., -3.4219e-02,\n",
      "           -4.4835e-02, -5.8720e-02],\n",
      "          [-8.1591e-02, -6.4334e-02, -5.1812e-02,  ..., -7.3791e-02,\n",
      "           -7.9681e-02, -8.0521e-02]],\n",
      "\n",
      "         [[ 4.4098e-02,  1.3596e-01,  1.6571e-01,  ...,  1.9844e-01,\n",
      "            1.1761e-01,  4.0338e-02],\n",
      "          [ 1.6871e-01,  1.6242e-01,  1.2116e-01,  ...,  1.2745e-01,\n",
      "            2.4646e-02,  3.0785e-02],\n",
      "          [ 1.4981e-01,  1.2158e-01,  7.7311e-02,  ...,  4.5146e-02,\n",
      "            3.2379e-04,  3.2163e-02],\n",
      "          ...,\n",
      "          [ 6.8268e-02,  7.4393e-02,  7.6458e-02,  ...,  3.6111e-02,\n",
      "            6.4862e-02,  5.3351e-02],\n",
      "          [ 7.9396e-02,  7.4054e-02,  6.7954e-02,  ...,  5.9776e-02,\n",
      "            7.3073e-02,  7.8679e-02],\n",
      "          [ 1.0441e-01,  7.9478e-02,  8.4033e-02,  ...,  7.0025e-02,\n",
      "            6.6960e-02,  4.0888e-02]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1)): tensor([[[[ 0.0691, -0.1455, -0.2382,  ...,  0.0651,  0.1631, -0.2487],\n",
      "          [-0.0610, -0.2310, -0.0326,  ...,  0.0790,  0.1026, -0.2852],\n",
      "          [-0.0998, -0.0866,  0.1054,  ...,  0.0017,  0.0313, -0.1831],\n",
      "          ...,\n",
      "          [-0.0303,  0.0080, -0.0444,  ...,  0.0599, -0.0265,  0.0867],\n",
      "          [-0.0261,  0.0287, -0.0847,  ...,  0.0917, -0.0600,  0.0736],\n",
      "          [ 0.0006,  0.0061, -0.0650,  ...,  0.0863, -0.0620,  0.0200]],\n",
      "\n",
      "         [[-0.1007, -0.0690, -0.0491,  ..., -0.1488, -0.1592, -0.1325],\n",
      "          [-0.0988, -0.0585, -0.0783,  ..., -0.1006, -0.1271, -0.1287],\n",
      "          [-0.0578, -0.0847, -0.0993,  ..., -0.1400, -0.1638, -0.1541],\n",
      "          ...,\n",
      "          [-0.2102, -0.2306, -0.2204,  ..., -0.1272, -0.1461, -0.1476],\n",
      "          [-0.2436, -0.2617, -0.2339,  ..., -0.1495, -0.1643, -0.1500],\n",
      "          [-0.2373, -0.2325, -0.2191,  ..., -0.1752, -0.1696, -0.1735]],\n",
      "\n",
      "         [[ 0.1042,  0.0685, -0.3590,  ..., -0.2758,  0.1667, -0.0047],\n",
      "          [ 0.0885, -0.1468, -0.3628,  ..., -0.1802,  0.2020, -0.1454],\n",
      "          [-0.1005, -0.2884, -0.1579,  ..., -0.1321,  0.0874, -0.1871],\n",
      "          ...,\n",
      "          [-0.0602,  0.0056, -0.0647,  ..., -0.0202, -0.0821,  0.0440],\n",
      "          [-0.0933,  0.0179, -0.0459,  ..., -0.0137, -0.0609, -0.0188],\n",
      "          [-0.0699, -0.0198, -0.0688,  ...,  0.0143, -0.0170, -0.1199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1074, -0.1175,  0.0663,  ...,  0.0274, -0.0067, -0.1023],\n",
      "          [-0.0798,  0.0407,  0.1714,  ..., -0.0548, -0.1386, -0.0799],\n",
      "          [ 0.0424,  0.1724,  0.0632,  ..., -0.1128, -0.1150, -0.1122],\n",
      "          ...,\n",
      "          [-0.0394, -0.0244, -0.1057,  ..., -0.0551, -0.0847, -0.0727],\n",
      "          [-0.0205, -0.0251, -0.1083,  ..., -0.0579, -0.1377, -0.0652],\n",
      "          [-0.0551, -0.0660,  0.0128,  ..., -0.0501, -0.0929, -0.1017]],\n",
      "\n",
      "         [[ 0.0729,  0.0443, -0.0100,  ...,  0.0018,  0.0195,  0.0699],\n",
      "          [ 0.0664,  0.0267, -0.0656,  ...,  0.0175,  0.0079,  0.0232],\n",
      "          [-0.0296, -0.0480, -0.0925,  ...,  0.0043,  0.0122, -0.0269],\n",
      "          ...,\n",
      "          [-0.0193, -0.0262, -0.0512,  ..., -0.0959, -0.0941, -0.0809],\n",
      "          [-0.0206, -0.0117, -0.0076,  ..., -0.0893, -0.0928, -0.0937],\n",
      "          [-0.0348, -0.0157,  0.0186,  ..., -0.0672, -0.0642, -0.0903]],\n",
      "\n",
      "         [[-0.4731, -0.4433, -0.3825,  ..., -0.2688, -0.2693, -0.2170],\n",
      "          [-0.3708, -0.3497, -0.3484,  ..., -0.3185, -0.1933, -0.1249],\n",
      "          [-0.3605, -0.2815, -0.1938,  ..., -0.0919, -0.0432, -0.0783],\n",
      "          ...,\n",
      "          [-0.1968, -0.1636, -0.1780,  ..., -0.1791, -0.1765, -0.1599],\n",
      "          [-0.1572, -0.1424, -0.1849,  ..., -0.1291, -0.1652, -0.1672],\n",
      "          [-0.1814, -0.1772, -0.1744,  ..., -0.1555, -0.1778, -0.1473]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True): tensor([[[[ 4.4390e-01, -1.7619e+00, -2.7147e+00,  ...,  4.0297e-01,\n",
      "            1.4099e+00, -2.8224e+00],\n",
      "          [-8.9343e-01, -2.6400e+00, -6.0177e-01,  ...,  5.4587e-01,\n",
      "            7.8842e-01, -3.1970e+00],\n",
      "          [-1.2924e+00, -1.1564e+00,  8.1726e-01,  ..., -2.4869e-01,\n",
      "            5.4907e-02, -2.1477e+00],\n",
      "          ...,\n",
      "          [-5.7793e-01, -1.8446e-01, -7.2216e-01,  ...,  3.4907e-01,\n",
      "           -5.3853e-01,  6.2522e-01],\n",
      "          [-5.3475e-01,  2.8520e-02, -1.1370e+00,  ...,  6.7568e-01,\n",
      "           -8.8313e-01,  4.9015e-01],\n",
      "          [-2.5985e-01, -2.0376e-01, -9.3445e-01,  ...,  6.2102e-01,\n",
      "           -9.0359e-01, -6.0547e-02]],\n",
      "\n",
      "         [[ 9.5205e-01,  1.6807e+00,  2.1372e+00,  ..., -1.5281e-01,\n",
      "           -3.9031e-01,  2.2122e-01],\n",
      "          [ 9.9642e-01,  1.9208e+00,  1.4667e+00,  ...,  9.5358e-01,\n",
      "            3.4598e-01,  3.0982e-01],\n",
      "          [ 1.9375e+00,  1.3205e+00,  9.8321e-01,  ...,  5.0538e-02,\n",
      "           -4.9728e-01, -2.7500e-01],\n",
      "          ...,\n",
      "          [-1.5621e+00, -2.0316e+00, -1.7965e+00,  ...,  3.4367e-01,\n",
      "           -9.0451e-02, -1.2549e-01],\n",
      "          [-2.3288e+00, -2.7461e+00, -2.1066e+00,  ..., -1.6851e-01,\n",
      "           -5.0938e-01, -1.8055e-01],\n",
      "          [-2.1856e+00, -2.0744e+00, -1.7663e+00,  ..., -7.5806e-01,\n",
      "           -6.3133e-01, -7.1969e-01]],\n",
      "\n",
      "         [[ 1.1975e+00,  8.9637e-01, -2.7087e+00,  ..., -2.0069e+00,\n",
      "            1.7246e+00,  2.7931e-01],\n",
      "          [ 1.0648e+00, -9.1933e-01, -2.7403e+00,  ..., -1.2011e+00,\n",
      "            2.0225e+00, -9.0716e-01],\n",
      "          [-5.2866e-01, -2.1129e+00, -1.0125e+00,  ..., -7.9513e-01,\n",
      "            1.0555e+00, -1.2593e+00],\n",
      "          ...,\n",
      "          [-1.8883e-01,  3.6621e-01, -2.2673e-01,  ...,  1.4824e-01,\n",
      "           -3.7342e-01,  6.8982e-01],\n",
      "          [-4.6836e-01,  4.7015e-01, -6.7914e-02,  ...,  2.0360e-01,\n",
      "           -1.9497e-01,  1.5990e-01],\n",
      "          [-2.7086e-01,  1.5180e-01, -2.6136e-01,  ...,  4.3954e-01,\n",
      "            1.7584e-01, -6.9267e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1999e-01, -7.2905e-01,  1.2506e+00,  ...,  8.3265e-01,\n",
      "            4.6507e-01, -5.6457e-01],\n",
      "          [-3.2199e-01,  9.7534e-01,  2.3837e+00,  ..., -5.3030e-02,\n",
      "           -9.5619e-01, -3.2408e-01],\n",
      "          [ 9.9385e-01,  2.3940e+00,  1.2182e+00,  ..., -6.7800e-01,\n",
      "           -7.0217e-01, -6.7143e-01],\n",
      "          ...,\n",
      "          [ 1.1272e-01,  2.7424e-01, -6.0097e-01,  ..., -5.5950e-02,\n",
      "           -3.7532e-01, -2.4652e-01],\n",
      "          [ 3.1669e-01,  2.6699e-01, -6.2962e-01,  ..., -8.6626e-02,\n",
      "           -9.4635e-01, -1.6511e-01],\n",
      "          [-5.6203e-02, -1.7427e-01,  6.7504e-01,  ..., -2.4468e-03,\n",
      "           -4.6377e-01, -5.5841e-01]],\n",
      "\n",
      "         [[ 3.0089e+00,  2.3629e+00,  1.1387e+00,  ...,  1.4046e+00,\n",
      "            1.8035e+00,  2.9430e+00],\n",
      "          [ 2.8623e+00,  1.9676e+00, -1.1676e-01,  ...,  1.7596e+00,\n",
      "            1.5433e+00,  1.8881e+00],\n",
      "          [ 6.9585e-01,  2.8037e-01, -7.2380e-01,  ...,  1.4603e+00,\n",
      "            1.6385e+00,  7.5662e-01],\n",
      "          ...,\n",
      "          [ 9.2754e-01,  7.7196e-01,  2.0882e-01,  ..., -8.0077e-01,\n",
      "           -7.5913e-01, -4.6271e-01],\n",
      "          [ 8.9944e-01,  1.0990e+00,  1.1917e+00,  ..., -6.5177e-01,\n",
      "           -7.2970e-01, -7.5084e-01],\n",
      "          [ 5.7862e-01,  1.0088e+00,  1.7848e+00,  ..., -1.5376e-01,\n",
      "           -8.5809e-02, -6.7385e-01]],\n",
      "\n",
      "         [[-2.6474e+00, -2.3597e+00, -1.7727e+00,  ..., -6.7533e-01,\n",
      "           -6.8022e-01, -1.7628e-01],\n",
      "          [-1.6601e+00, -1.4560e+00, -1.4434e+00,  ..., -1.1550e+00,\n",
      "            5.2994e-02,  7.1325e-01],\n",
      "          [-1.5607e+00, -7.9842e-01,  4.7989e-02,  ...,  1.0313e+00,\n",
      "            1.5010e+00,  1.1623e+00],\n",
      "          ...,\n",
      "          [ 1.9426e-02,  3.3915e-01,  2.0045e-01,  ...,  1.8993e-01,\n",
      "            2.1501e-01,  3.7497e-01],\n",
      "          [ 4.0103e-01,  5.4391e-01,  1.3421e-01,  ...,  6.7245e-01,\n",
      "            3.2408e-01,  3.0491e-01],\n",
      "          [ 1.6803e-01,  2.0799e-01,  2.3476e-01,  ...,  4.1722e-01,\n",
      "            2.0256e-01,  4.9670e-01]]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>), Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1)): tensor([[[[-1.4353e+00, -8.8107e-01, -1.5078e+00,  ..., -7.5939e-01,\n",
      "           -1.6637e+00, -1.0533e+00],\n",
      "          [-2.8450e+00, -5.6424e-01, -1.7258e+00,  ..., -1.4893e-03,\n",
      "           -9.5287e-01, -1.3027e+00],\n",
      "          [-1.2186e+00, -1.2522e+00, -3.1235e+00,  ..., -6.0758e-01,\n",
      "           -1.4276e-01, -1.7892e-01],\n",
      "          ...,\n",
      "          [ 2.0765e-01, -3.8127e-01,  1.6831e+00,  ..., -2.8956e+00,\n",
      "           -2.2180e+00, -2.1819e+00],\n",
      "          [ 2.8725e-01, -5.6847e-01,  1.4656e+00,  ..., -4.7310e-01,\n",
      "           -8.7812e-01, -1.3610e+00],\n",
      "          [ 3.5634e-01, -6.5070e-02,  2.8931e-01,  ...,  1.0638e-02,\n",
      "           -2.2851e-01, -4.0361e-01]],\n",
      "\n",
      "         [[-3.1351e+00, -1.8663e+00, -4.7435e+00,  ...,  4.8719e-01,\n",
      "            1.7639e-02,  4.3743e-01],\n",
      "          [-4.2348e-01, -4.1179e-01, -1.5560e+00,  ...,  1.4973e+00,\n",
      "            5.0939e-01,  8.1380e-02],\n",
      "          [ 5.2404e-01, -5.1129e-01, -3.7236e-01,  ..., -4.2530e-01,\n",
      "           -3.7239e-01, -6.5893e-01],\n",
      "          ...,\n",
      "          [-2.8425e-01, -8.0691e-01,  5.3658e-01,  ..., -3.3775e-01,\n",
      "           -9.0312e-01, -7.5060e-01],\n",
      "          [-3.4495e-01, -1.3173e+00, -7.0040e-01,  ...,  1.1805e-01,\n",
      "            1.0081e+00, -6.8006e-02],\n",
      "          [-6.9388e-01, -5.9879e-01, -1.3254e+00,  ..., -3.7263e-01,\n",
      "            1.8770e-01, -3.6393e-01]],\n",
      "\n",
      "         [[-1.1315e-01, -4.3488e-01, -5.0758e-01,  ..., -2.2065e+00,\n",
      "           -1.0161e+00, -1.6940e+00],\n",
      "          [-3.2997e-01,  9.8873e-04, -2.2961e-01,  ..., -2.0155e+00,\n",
      "           -2.1291e+00, -2.1140e+00],\n",
      "          [ 5.4318e-04, -3.8040e-01, -2.5332e+00,  ..., -1.3130e+00,\n",
      "           -9.8017e-01, -8.8269e-01],\n",
      "          ...,\n",
      "          [-2.0114e-01,  7.2943e-02,  3.5858e-03,  ...,  1.1790e-01,\n",
      "           -3.3748e-01, -3.9517e-01],\n",
      "          [-3.9025e-01, -2.1734e-01,  1.7090e-01,  ..., -2.9154e-01,\n",
      "           -5.9023e-01, -6.5454e-01],\n",
      "          [-8.9957e-01, -3.9882e-01,  5.7066e-02,  ..., -2.8444e-01,\n",
      "           -1.4122e-01, -6.9212e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3927e+00, -1.7394e+00, -6.5473e-01,  ...,  2.6017e-01,\n",
      "            3.2916e-01, -9.4699e-01],\n",
      "          [-9.9549e-01, -1.1890e+00, -3.6882e-01,  ...,  2.3661e-01,\n",
      "            3.4162e-01, -4.4368e-02],\n",
      "          [ 1.0178e-01, -3.2590e-01, -1.5026e+00,  ...,  1.1529e-01,\n",
      "            6.6654e-01, -2.0984e-01],\n",
      "          ...,\n",
      "          [ 2.0571e-02,  1.2135e-01, -7.0247e-02,  ..., -9.2585e-01,\n",
      "            4.1462e-03, -1.7488e-01],\n",
      "          [-3.4510e-01, -2.8964e-01,  5.0406e-01,  ..., -3.5937e-01,\n",
      "           -4.4672e-01, -5.9130e-01],\n",
      "          [-2.2649e-01,  2.2274e-01,  8.9204e-02,  ...,  5.7757e-01,\n",
      "           -6.9510e-02, -6.4048e-02]],\n",
      "\n",
      "         [[ 3.7034e-01, -2.0837e+00, -3.7171e+00,  ...,  2.7829e-01,\n",
      "            1.1695e+00,  2.7799e-01],\n",
      "          [ 1.9528e-01, -3.7387e-01, -4.1781e-01,  ..., -6.2553e-01,\n",
      "           -4.9094e-01,  5.7933e-01],\n",
      "          [ 4.2335e-01,  9.9604e-02, -4.5941e-01,  ...,  3.9539e-01,\n",
      "            9.1153e-01,  1.0407e+00],\n",
      "          ...,\n",
      "          [ 1.8836e-01,  1.2926e-01,  1.6160e+00,  ...,  1.1309e+00,\n",
      "            1.3943e+00, -9.7119e-02],\n",
      "          [-1.5077e-01, -7.8205e-02,  2.0701e-01,  ...,  2.3672e+00,\n",
      "            9.8297e-01,  3.7235e-01],\n",
      "          [-3.5250e-01, -6.2227e-01, -6.3301e-01,  ...,  6.1655e-01,\n",
      "            2.5635e-01,  2.0730e-01]],\n",
      "\n",
      "         [[-1.0417e+00, -3.7012e+00, -5.6793e+00,  ...,  3.9828e-01,\n",
      "            1.1516e+00,  1.4207e+00],\n",
      "          [-3.9026e-01, -1.3932e+00, -1.6022e+00,  ...,  9.8724e-01,\n",
      "            1.1722e+00,  2.1319e+00],\n",
      "          [-3.4355e-01, -3.8151e-02, -8.0159e-01,  ...,  4.2568e-01,\n",
      "            8.8072e-01,  1.8849e+00],\n",
      "          ...,\n",
      "          [-3.2377e-01, -3.9636e-01,  6.8019e-02,  ...,  3.7005e-01,\n",
      "            1.0821e+00,  8.2702e-01],\n",
      "          [-6.6624e-01, -1.2833e+00, -1.0058e+00,  ...,  2.3283e+00,\n",
      "            1.8956e+00,  6.6275e-01],\n",
      "          [-1.0149e+00, -1.4929e+00, -1.6813e+00,  ...,  9.2540e-01,\n",
      "            6.1362e-01,  3.6487e-01]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1)): tensor([[[[ 0.3978,  0.8030,  0.2643,  ..., -0.4679, -1.5445, -2.2947],\n",
      "          [ 0.2200, -0.3659,  0.0735,  ..., -0.2258, -0.3061, -0.4662],\n",
      "          [-0.8245, -0.4163,  0.3018,  ..., -0.5752, -0.1562,  0.1314],\n",
      "          ...,\n",
      "          [-0.4947, -0.3501, -0.6258,  ...,  0.4603, -0.6952, -2.0692],\n",
      "          [-0.0466,  0.1867, -0.7234,  ..., -0.0476, -1.1794, -1.9635],\n",
      "          [-0.2752,  0.0992,  0.1043,  ...,  0.3040, -1.0958, -1.3829]],\n",
      "\n",
      "         [[-0.6303,  0.2856, -0.6262,  ...,  0.2925,  0.2330, -0.1911],\n",
      "          [-0.0800,  0.5438,  0.0639,  ..., -0.0659, -0.0395,  0.1336],\n",
      "          [ 1.0367,  1.0940,  1.1888,  ..., -0.1191,  0.4292,  0.4310],\n",
      "          ...,\n",
      "          [-0.8813, -1.6116, -1.3950,  ...,  1.3504,  1.4390,  1.1262],\n",
      "          [-0.6785, -1.1059, -0.8305,  ...,  0.7846,  0.3892, -0.1145],\n",
      "          [-0.0587, -0.4788, -1.2318,  ..., -0.9201, -1.2026, -0.9914]],\n",
      "\n",
      "         [[ 2.5812,  2.6716, -0.0350,  ...,  0.6552,  0.3617,  0.1222],\n",
      "          [ 0.6388,  0.0865, -0.5989,  ..., -2.0613, -1.5324, -1.3180],\n",
      "          [ 1.1637,  0.7417,  0.2224,  ..., -1.1809, -1.0576, -1.3195],\n",
      "          ...,\n",
      "          [-0.0528,  0.6118,  2.0869,  ...,  0.3465,  0.3890, -0.0477],\n",
      "          [-0.6200, -0.2254,  1.8914,  ...,  0.6971,  1.1345,  1.2257],\n",
      "          [-0.6761, -1.1030, -0.6707,  ..., -1.2285, -0.3093,  0.1371]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0483,  2.9729,  3.9007,  ...,  0.8942,  0.0183, -0.8653],\n",
      "          [-0.8135,  0.0859,  1.3286,  ...,  0.1828,  0.0637, -0.6130],\n",
      "          [-1.1103,  0.2623, -0.0140,  ..., -0.2268,  0.3482, -0.3435],\n",
      "          ...,\n",
      "          [ 0.0055, -0.9667, -2.3678,  ..., -0.7605, -0.1208,  0.6165],\n",
      "          [-0.0888, -0.6271, -0.9376,  ...,  1.3220,  1.5578,  1.3490],\n",
      "          [-0.1549, -0.5994, -1.3531,  ...,  0.5823,  1.4888,  1.2730]],\n",
      "\n",
      "         [[-1.7506, -1.4873, -1.5388,  ..., -2.4876, -2.2485, -2.1877],\n",
      "          [-2.6637, -1.2193, -0.8236,  ..., -1.9737, -1.7172, -1.8989],\n",
      "          [-1.9882, -0.3743, -0.2499,  ..., -2.4447, -1.0958, -0.6984],\n",
      "          ...,\n",
      "          [-0.2718, -2.7318, -2.9167,  ...,  0.2391, -0.5733, -0.4962],\n",
      "          [ 0.4454, -1.9369, -2.1254,  ..., -0.4757, -1.0631, -0.5951],\n",
      "          [ 0.5557, -0.7516, -1.3736,  ...,  0.8469, -0.4510,  0.0265]],\n",
      "\n",
      "         [[ 0.2118, -0.2325,  0.0458,  ...,  2.1023,  1.9508,  0.9930],\n",
      "          [ 0.6710,  0.5134,  0.9312,  ...,  2.6112,  1.7881,  0.7416],\n",
      "          [ 2.5555,  1.2424,  1.1256,  ...,  1.7754,  0.8766,  0.1871],\n",
      "          ...,\n",
      "          [-0.4006, -0.8160, -0.2995,  ...,  1.3369,  0.5345,  0.1592],\n",
      "          [-0.0370, -0.5324, -0.7131,  ...,  1.9125,  0.9872,  0.7723],\n",
      "          [-0.1013, -0.2239, -0.3317,  ...,  0.6597, -0.5820, -0.5239]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True): tensor([[[[ 0.5637,  1.0616,  0.3995,  ..., -0.5004, -1.8238, -2.7460],\n",
      "          [ 0.3450, -0.3751,  0.1649,  ..., -0.2030, -0.3016, -0.4984],\n",
      "          [-0.9388, -0.4370,  0.4456,  ..., -0.6324, -0.1174,  0.2361],\n",
      "          ...,\n",
      "          [-0.5334, -0.3557, -0.6946,  ...,  0.6404, -0.7798, -2.4687],\n",
      "          [ 0.0174,  0.3041, -0.8146,  ...,  0.0161, -1.3751, -2.3388],\n",
      "          [-0.2637,  0.1966,  0.2028,  ...,  0.4484, -1.2723, -1.6252]],\n",
      "\n",
      "         [[-1.0345,  0.1255, -1.0293,  ...,  0.1343,  0.0589, -0.4782],\n",
      "          [-0.3375,  0.4525, -0.1553,  ..., -0.3197, -0.2863, -0.0669],\n",
      "          [ 1.0768,  1.1494,  1.2695,  ..., -0.3871,  0.3074,  0.3097],\n",
      "          ...,\n",
      "          [-1.3524, -2.2773, -2.0030,  ...,  1.4741,  1.5863,  1.1902],\n",
      "          [-1.0955, -1.6368, -1.2880,  ...,  0.7575,  0.2567, -0.3812],\n",
      "          [-0.3106, -0.8426, -1.7962,  ..., -1.4015, -1.7593, -1.4919]],\n",
      "\n",
      "         [[ 1.8756,  1.9479, -0.2170,  ...,  0.3350,  0.1003, -0.0913],\n",
      "          [ 0.3219, -0.1198, -0.6681,  ..., -1.8378, -1.4147, -1.2432],\n",
      "          [ 0.7418,  0.4042, -0.0111,  ..., -1.1336, -1.0350, -1.2445],\n",
      "          ...,\n",
      "          [-0.2312,  0.3003,  1.4802,  ...,  0.0881,  0.1221, -0.2272],\n",
      "          [-0.6849, -0.3693,  1.3238,  ...,  0.3686,  0.7184,  0.7913],\n",
      "          [-0.7298, -1.0713, -0.7255,  ..., -1.1717, -0.4364, -0.0794]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4415,  2.1814,  2.9239,  ...,  0.5180, -0.1829, -0.8900],\n",
      "          [-0.8486, -0.1288,  0.8657,  ..., -0.0513, -0.1466, -0.6881],\n",
      "          [-1.0861,  0.0123, -0.2088,  ..., -0.3791,  0.0811, -0.4725],\n",
      "          ...,\n",
      "          [-0.1932, -0.9711, -2.0924,  ..., -0.8062, -0.2942,  0.2958],\n",
      "          [-0.2686, -0.6994, -0.9479,  ...,  0.8603,  1.0490,  0.8819],\n",
      "          [-0.3215, -0.6772, -1.2804,  ...,  0.2684,  0.9938,  0.8211]],\n",
      "\n",
      "         [[-0.7375, -0.4869, -0.5359,  ..., -1.4390, -1.2113, -1.1535],\n",
      "          [-1.6065, -0.2318,  0.1447,  ..., -0.9499, -0.7057, -0.8786],\n",
      "          [-0.9636,  0.5723,  0.6906,  ..., -1.3981, -0.1144,  0.2639],\n",
      "          ...,\n",
      "          [ 0.6698, -1.6713, -1.8473,  ...,  1.1560,  0.3829,  0.4562],\n",
      "          [ 1.3524, -0.9148, -1.0942,  ...,  0.4758, -0.0833,  0.3621],\n",
      "          [ 1.4573,  0.2132, -0.3787,  ...,  1.7345,  0.4993,  0.9537]],\n",
      "\n",
      "         [[-1.0258, -1.5481, -1.2210,  ...,  1.1968,  1.0187, -0.1074],\n",
      "          [-0.4860, -0.6712, -0.1800,  ...,  1.7950,  0.8273, -0.4029],\n",
      "          [ 1.7295,  0.1858,  0.0485,  ...,  0.8125, -0.2443, -1.0549],\n",
      "          ...,\n",
      "          [-1.7458, -2.2341, -1.6268,  ...,  0.2969, -0.6464, -1.0877],\n",
      "          [-1.3183, -1.9007, -2.1131,  ...,  0.9736, -0.1141, -0.3669],\n",
      "          [-1.3938, -1.5380, -1.6647,  ..., -0.4992, -1.9590, -1.8907]]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward>), Linear(in_features=1600, out_features=10, bias=True): tensor([[-15.0877, -14.0018, -12.8760, -10.9865, -10.2681, -10.2374, -14.2335,\n",
      "         -14.1889, -13.9181, -14.7917]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)}\n"
     ]
    }
   ],
   "source": [
    "#Task C-2\n",
    "\n",
    "def hook_function(model, input, output):\n",
    "    feature_maps[model]=output\n",
    "\n",
    "def get_layers(net):\n",
    "    for name, layer in net._modules.items():\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            get_layers(layer)\n",
    "        else:\n",
    "            layer.register_forward_hook(hook_function)\n",
    "\n",
    "feature_maps={}\n",
    "get_layers(model1)\n",
    "image_data=dataset_y2[image_index][0].unsqueeze_(0)\n",
    "image_data=image_data.to('cuda:0')\n",
    "prediction = model1(image_data)\n",
    "\n",
    "print(feature_maps)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}